{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "236fa257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tantivy\n",
    "# %pip install git+https://github.com/Eventual-Inc/Daft.git\n",
    "# %pip install lancedb\n",
    "# %pip install git+https://github.com/auxon/griptape.git\n",
    "# %pip install cloudpickle\n",
    "# %pip install ray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8773618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import cloudpickle\n",
    "import ray\n",
    "\n",
    "def serialize_sqlite_connection(conn):\n",
    "    return ray.data.datasource\n",
    "\n",
    "def deserialize_sqlite_connection(path):\n",
    "    return sqlite3.connect(path)\n",
    "\n",
    "# Register the custom serializer with cloudpickle\n",
    "cloudpickle.register_pickle_by_value(sqlite3)\n",
    "cloudpickle.CloudPickler.dispatch[sqlite3.Connection] = serialize_sqlite_connection\n",
    "\n",
    "# Register the custom serializer with Ray\n",
    "ray.util.register_serializer(\n",
    "    sqlite3.Connection,\n",
    "    serializer=serialize_sqlite_connection,\n",
    "    deserializer=deserialize_sqlite_connection\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d792207d-f0cc-43d5-a3e5-01b26629e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, EmailStr, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class EmailModel(BaseModel):\n",
    "    sender: EmailStr = Field(..., description=\"Sender's email address\")\n",
    "    subject: str = Field(..., description=\"Subject of the email\")\n",
    "    content: str = Field(..., description=\"Content of the email\")\n",
    "    namespace: Optional[str] = Field(default=None, description=\"Namespace for the email\")\n",
    "    meta: Optional[str] = Field(default=None, description=\"Metadata for the email\")\n",
    "    vector: Optional[List[float]] = Field(default=None, description=\"Vector of content for the email\")\n",
    "\n",
    "class EmailListModel(BaseModel):\n",
    "    emails: List[EmailModel] = Field(..., description=\"List of emails\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40518308-837a-42ce-9f13-52b59fa6b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "from typing import List, Dict, Optional\n",
    "from attrs import define, field\n",
    "from pydantic import BaseModel, EmailStr\n",
    "from griptape.mixins import SerializableMixin, FuturesExecutorMixin\n",
    "from lancedb.pydantic import pydantic_to_schema\n",
    "\n",
    "class EmailEntryModel(BaseModel):\n",
    "    id: str = Field(..., description=\"Unique identifier for the email\")\n",
    "    sender: str = Field(..., description=\"Sender's email address\")\n",
    "    subject: str = Field(..., description=\"Subject of the email\")\n",
    "    content: str = Field(..., description=\"Content of the email\")\n",
    "    namespace: Optional[str] = Field(default=None, description=\"Namespace for the email\")\n",
    "    meta: Optional[str] = Field(default=None, description=\"Metadata for the email\")\n",
    "    vector: Optional[List[float]] = Field(default=None, description=\"Vectors of content for the email\")\n",
    "\n",
    "@define\n",
    "class PydanticPyArrowDaftRayLanceDBDriver(SerializableMixin, FuturesExecutorMixin):\n",
    "    lancedb_path: str = field(kw_only=True, default=\"lancedb_dir\", metadata={\"serializable\": True})\n",
    "    table_name: str = field(kw_only=True, default=\"emails\", metadata={\"serializable\": True})\n",
    "\n",
    "    def __attrs_post_init__(self):\n",
    "        # Initialize LanceDB connection\n",
    "        self.lancedb = lancedb.connect(self.lancedb_path)\n",
    "        \n",
    "        # Check if the table exists and delete it if it does\n",
    "        if self.table_name in self.lancedb.table_names():\n",
    "            self.lancedb.drop_table(self.table_name)\n",
    "            print(f\"Dropped existing table: {self.table_name}\")\n",
    "        \n",
    "        # Create LanceDB table using PyArrow schema\n",
    "        schema = pa.schema([\n",
    "            pa.field('id', pa.string()),\n",
    "            pa.field('sender', pa.string()),\n",
    "            pa.field('subject', pa.string()),\n",
    "            pa.field('content', pa.string()),\n",
    "            pa.field('namespace', pa.string()),\n",
    "            pa.field('meta', pa.string()),\n",
    "            pa.field('vector', pa.list_(pa.float32()))  # Add vector column\n",
    "        ])\n",
    "        table = self.lancedb.create_table(self.table_name, schema=schema)\n",
    "        print(f\"Created table with schema: {table.schema}\")\n",
    "\n",
    "\n",
    "    def upsert_email(self, email: EmailModel, *, email_id: Optional[str] = None, namespace: Optional[str] = None, meta: Optional[Dict] = None) -> str:\n",
    "        if email_id is None:\n",
    "            email_id = self._get_default_id(str(email.dict()))\n",
    "\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        print(f\"Table schema before upsert: {table.schema}\")\n",
    "\n",
    "        # Generate a dummy vector (e.g., a list of floats)\n",
    "        vector = [0.0] * 128  # Example: 128-dimensional zero vector\n",
    "\n",
    "        data = EmailEntryModel(\n",
    "            id=email_id,\n",
    "            sender=str(email.sender),\n",
    "            subject=email.subject,\n",
    "            content=email.content,\n",
    "            namespace=email.namespace,\n",
    "            meta=email.meta,\n",
    "            vector=email.vector \n",
    "        )\n",
    "        print(f\"Data to be inserted: {data.model_dump()}\")\n",
    "\n",
    "        # Ensure all fields are included in the dictionary\n",
    "        data_dict = data.model_dump()\n",
    "        for field in ['namespace', 'meta', 'vector']:\n",
    "            if field not in data_dict:\n",
    "                data_dict[field] = None\n",
    "        data_dict['vector'] = vector  # Add the vector to the data\n",
    "\n",
    "        # Define the schema explicitly\n",
    "        schema = pa.schema([\n",
    "            pa.field('id', pa.string()),\n",
    "            pa.field('sender', pa.string()),\n",
    "            pa.field('subject', pa.string()),\n",
    "            pa.field('content', pa.string()),\n",
    "            pa.field('namespace', pa.string()),\n",
    "            pa.field('meta', pa.string()),\n",
    "            pa.field('vector', pa.list_(pa.float32()))  # Ensure vector column is included\n",
    "        ])\n",
    "\n",
    "        # Convert to PyArrow Table with the defined schema\n",
    "        pyarrow_table = pa.Table.from_pydict({k: [v] for k, v in data_dict.items()}, schema=schema)\n",
    "        print(f\"PyArrow table schema: {pyarrow_table.schema}\")\n",
    "        table.add(pyarrow_table, mode=\"overwrite\")\n",
    "\n",
    "        return email_id\n",
    "\n",
    "    def load_email(self, email_id: str, *, namespace: Optional[str] = None) -> Optional[EmailEntryModel]:\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        query = table.search(f\"id == '{email_id}'\")\n",
    "\n",
    "        if namespace:\n",
    "            query = query.filter(f\"namespace == '{namespace}'\")\n",
    "\n",
    "        result = query.to_pandas().to_dict(orient=\"records\")\n",
    "        if result:\n",
    "            return EmailEntryModel(**result[0])\n",
    "        return None\n",
    "\n",
    "    def load_all_emails(self, *, namespace: Optional[str] = None) -> List[EmailEntryModel]:\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "\n",
    "        if namespace:\n",
    "            results = table.search(f\"namespace == '{namespace}'\").to_pandas().to_dict(orient=\"records\")\n",
    "        else:\n",
    "            results = table.to_pandas().to_dict(orient=\"records\")\n",
    "\n",
    "        return [EmailEntryModel(**r) for r in results]\n",
    "\n",
    "    def delete_email(self, email_id: str) -> None:\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        table.delete(f\"id == '{email_id}'\")\n",
    "\n",
    "    def query_by_sender(\n",
    "        self,\n",
    "        sender: EmailStr,\n",
    "        *,\n",
    "        count: Optional[int] = None,\n",
    "        namespace: Optional[str] = None,\n",
    "    ) -> List[EmailEntryModel]:\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        query = table.search(f\"sender == '{sender}'\", vector_column_name=\"vector\")\n",
    "\n",
    "        if namespace:\n",
    "            query = query.filter(f\"namespace == '{namespace}'\")\n",
    "\n",
    "        query = query.limit(count or 10)\n",
    "        results = query.to_pandas().to_dict(orient=\"records\")\n",
    "\n",
    "        return [EmailEntryModel(**r) for r in results]\n",
    "\n",
    "    def _get_default_id(self, value: str) -> str:\n",
    "        return str(uuid.uuid5(uuid.NAMESPACE_OID, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c87b5f-e94d-40df-89ae-63fac93524a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 13:27:01,806\tINFO worker.py:1783 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import daft\n",
    "import ray\n",
    "from griptape.tasks import BaseTask\n",
    "from griptape.artifacts import TextArtifact\n",
    "\n",
    "class EmailProcessingWorkflow(BaseTask):\n",
    "    def __init__(self, lancedb_path: str):\n",
    "        super().__init__()\n",
    "        self.lancedb_path = lancedb_path\n",
    "        ray.shutdown()\n",
    "        ray.init()\n",
    "        daft.set_execution_config(enable_native_executor=True)  # Enable Ray execution\n",
    "        \n",
    "\n",
    "    def run(self, input_data: EmailListModel):\n",
    "        # Convert input data to Daft DataFrame\n",
    "        data = {\n",
    "            \"senders\": [email.sender for email in input_data.emails],\n",
    "            \"subjects\": [email.subject for email in input_data.emails],\n",
    "            \"contents\": [email.content for email in input_data.emails],\n",
    "            \"namespace\": [email.namespace for email in input_data.emails],\n",
    "            \"meta\": [email.meta for email in input_data.emails],\n",
    "            \"vector\": [email.vector for email in input_data.emails],\n",
    "        }\n",
    "        df = daft.from_pydict(data)  # Create a LogicalPlanBuilder\n",
    "\n",
    "        # Process data using Daft (this will be executed on Ray)\n",
    "        df = df.with_column(\"domain\", df[\"senders\"].str.split(\"@\").list.get(-1))\n",
    "        df = df.with_column(\"word_count\", df[\"contents\"].str.split(\" \").list.lengths())\n",
    "\n",
    "        # Write results to LanceDB\n",
    "        df.write_lance(self.lancedb_path)\n",
    "\n",
    "        # Convert Daft DataFrame to Pandas DataFrame for display\n",
    "        result_df = df.to_pandas()\n",
    "\n",
    "        return TextArtifact(f\"Processed data:\\n{result_df}\")\n",
    "\n",
    "    def input(self) -> EmailListModel:\n",
    "        return EmailListModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98914b53-4eb5-4f67-9d48-92405139c281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped existing table: emails\n",
      "Created table with schema: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Table schema before upsert: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Data to be inserted: {'id': '7caf2b1a-a72f-58c6-b95d-369ccdb47213', 'sender': 'alice@example.com', 'subject': 'Meeting', 'content': \"Let's meet at 10 AM.\", 'namespace': 'personal', 'meta': 'location:office', 'vector': [0.1, 0.2, 0.3]}\n",
      "PyArrow table schema: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Table schema before upsert: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Data to be inserted: {'id': 'fefab10b-1ff4-562a-a037-f164ee4e8740', 'sender': 'bob@example.org', 'subject': 'Project Update', 'content': 'The project is on track.', 'namespace': 'work', 'meta': 'status:on track', 'vector': [0.4, 0.5, 0.6]}\n",
      "PyArrow table schema: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Table schema before upsert: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "Data to be inserted: {'id': '8f13a7f2-773b-5634-a8e0-52960e5e75ef', 'sender': 'carol@example.net', 'subject': 'Invoice', 'content': 'Please find the invoice attached.', 'namespace': 'work', 'meta': 'status:pending', 'vector': [0.7, 0.8, 0.9]}\n",
      "PyArrow table schema: id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: float>\n",
      "  child 0, item: float\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 13:27:05,781\tINFO worker.py:1783 -- Started a local Ray instance.\n",
      "thread 'python' panicked at src/daft-physical-plan/src/translate.rs:65:14:\n",
      "not yet implemented: Sink not yet implemented\n",
      "note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "not yet implemented: Sink not yet implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Run the processing workflow using Ray and Daft\u001b[39;00m\n\u001b[1;32m     26\u001b[0m workflow \u001b[38;5;241m=\u001b[39m EmailProcessingWorkflow(lancedb_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./lancedb_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m result_artifact \u001b[38;5;241m=\u001b[39m \u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Output the processed results\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_artifact\u001b[38;5;241m.\u001b[39mvalue)\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mEmailProcessingWorkflow.run\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwith_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword_count\u001b[39m\u001b[38;5;124m\"\u001b[39m, df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mlengths())\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Write results to LanceDB\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_lance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlancedb_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Convert Daft DataFrame to Pandas DataFrame for display\u001b[39;00m\n\u001b[1;32m     35\u001b[0m result_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_pandas()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/analytics.py:189\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    192\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    193\u001b[0m     )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:837\u001b[0m, in \u001b[0;36mDataFrame.write_lance\u001b[0;34m(self, uri, mode, io_config, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m builder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_builder\u001b[38;5;241m.\u001b[39mwrite_lance(\n\u001b[1;32m    831\u001b[0m     table_uri,\n\u001b[1;32m    832\u001b[0m     mode,\n\u001b[1;32m    833\u001b[0m     io_config\u001b[38;5;241m=\u001b[39mio_config,\n\u001b[1;32m    834\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m    835\u001b[0m )\n\u001b[1;32m    836\u001b[0m write_df \u001b[38;5;241m=\u001b[39m DataFrame(builder)\n\u001b[0;32m--> 837\u001b[0m \u001b[43mwrite_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m write_result \u001b[38;5;241m=\u001b[39m write_df\u001b[38;5;241m.\u001b[39mto_pydict()\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfragments\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m write_result\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/api_annotations.py:26\u001b[0m, in \u001b[0;36mDataframePublicAPI.<locals>._wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m type_check_function(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m timed_method \u001b[38;5;241m=\u001b[39m time_df_method(func)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimed_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/analytics.py:189\u001b[0m, in \u001b[0;36mtime_df_method.<locals>.tracked_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    191\u001b[0m     _ANALYTICS_CLIENT\u001b[38;5;241m.\u001b[39mtrack_df_method_call(\n\u001b[1;32m    192\u001b[0m         method_name\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, duration_seconds\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start, error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    193\u001b[0m     )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:2060\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, num_preview_rows)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;129m@DataframePublicAPI\u001b[39m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_preview_rows: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the entire DataFrame and materializes the results\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \n\u001b[1;32m   2051\u001b[0m \u001b[38;5;124;03m    .. NOTE::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;124;03m        DataFrame: DataFrame with materialized results.\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2060\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2062\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2063\u001b[0m     dataframe_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/dataframe/dataframe.py:2042\u001b[0m, in \u001b[0;36mDataFrame._materialize_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2040\u001b[0m context \u001b[38;5;241m=\u001b[39m get_context()\n\u001b[1;32m   2041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_cache \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2043\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[1;32m   2044\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:143\u001b[0m, in \u001b[0;36mPyRunner.run\u001b[0;34m(self, builder)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PartitionCacheEntry:\n\u001b[0;32m--> 143\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     result_pset \u001b[38;5;241m=\u001b[39m LocalPartitionSet()\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/runners/pyrunner.py:196\u001b[0m, in \u001b[0;36mPyRunner.run_iter\u001b[0;34m(self, builder, results_buffer_size)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m daft_execution_config\u001b[38;5;241m.\u001b[39menable_native_executor:\n\u001b[1;32m    195\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing native executor\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 196\u001b[0m     executor \u001b[38;5;241m=\u001b[39m \u001b[43mNativeExecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_logical_plan_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     results_gen \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    198\u001b[0m         {k: v\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_part_set_cache\u001b[38;5;241m.\u001b[39mget_all_partition_sets()\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    199\u001b[0m     )\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/daft/execution/native_executor.py:25\u001b[0m, in \u001b[0;36mNativeExecutor.from_logical_plan_builder\u001b[0;34m(cls, builder)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_logical_plan_builder\u001b[39m(\u001b[38;5;28mcls\u001b[39m, builder: LogicalPlanBuilder) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NativeExecutor:\n\u001b[0;32m---> 25\u001b[0m     executor \u001b[38;5;241m=\u001b[39m \u001b[43m_NativeExecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_logical_plan_builder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(executor)\n",
      "\u001b[0;31mPanicException\u001b[0m: not yet implemented: Sink not yet implemented"
     ]
    }
   ],
   "source": [
    "# Example email data\n",
    "input_data = EmailListModel(emails=[\n",
    "    EmailModel(sender=\"alice@example.com\", subject=\"Meeting\", content=\"Let's meet at 10 AM.\", namespace=\"personal\", meta=\"location:office\", vector=[0.1, 0.2, 0.3]),\n",
    "    EmailModel(sender=\"bob@example.org\", subject=\"Project Update\", content=\"The project is on track.\", namespace=\"work\", meta=\"status:on track\", vector=[0.4, 0.5, 0.6]),\n",
    "    EmailModel(sender=\"carol@example.net\", subject=\"Invoice\", content=\"Please find the invoice attached.\", namespace=\"work\", meta=\"status:pending\", vector=[0.7, 0.8, 0.9])\n",
    "])\n",
    "\n",
    "# Initialize the driver\n",
    "driver = PydanticPyArrowDaftRayLanceDBDriver(lancedb_path=\"./lancedb_dir\")\n",
    "\n",
    "# Upsert emails into LanceDB\n",
    "for email in input_data.emails:\n",
    "    driver.upsert_email(email)\n",
    "\n",
    "# Create the FTS index\n",
    "table = driver.lancedb.open_table(driver.table_name)\n",
    "table.create_fts_index(['sender', 'subject', 'content'])  # Add any other relevant fields\n",
    "\n",
    "# Now you can query emails by a specific sender\n",
    "queried_emails = driver.query_by_sender(\"alice@example.com\")\n",
    "\n",
    "# Print the queried result\n",
    "print(queried_emails)\n",
    "\n",
    "# Run the processing workflow using Ray and Daft\n",
    "workflow = EmailProcessingWorkflow(lancedb_path=\"./lancedb_dir\")\n",
    "result_artifact = workflow.run(input_data=input_data)\n",
    "\n",
    "# Output the processed results\n",
    "print(result_artifact.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
